{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# TUGAS PRAKTIKUM 2 MACHINE LEARNING #\n",
        "\n",
        "Mochammad Dzahwan Fadhloly || 24060121140168 || Lab ML A1"
      ],
      "metadata": {
        "id": "oXi8ApBjUaih"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Nomor 1\n",
        "\n",
        "Dataset Bunga Iris\n",
        "\n",
        "Link: http://archive.ics.uci.edu/dataset/53/iris"
      ],
      "metadata": {
        "id": "ThxsABPgVUUl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import Library yang Dibutuhkan**\n",
        "\n",
        "Pertama gunakan library pandas. Pandas merupakan sebuah library di Python yang berlisensi BSD dan open source yang menyediakan struktur data dan analisis data yang mudah digunakan."
      ],
      "metadata": {
        "id": "7xvjYx8Ontic"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "59mHNjqzha9j"
      },
      "outputs": [],
      "source": [
        "#import library yang dibutuhkan\n",
        "import pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Memuat Dataset**\n",
        "\n",
        "Pada tugas ini dataset yang digunakan adalah dataset klasifikasi Bunga Iris.\n",
        "\n",
        "Pertama definisikan variabel names untuk menyimpan nama-nama kolom atau atribut dari dataset. Setiap elemen dalam daftar names mewakili nama kolom yang ada dalam dataset.\n",
        "\n",
        "Kemudian digunakan library pandas untuk membaca dataset dari file CSV yang sudah diimport tadi yaitu dengan fungsi read_csv dan memasukkan dua argumen untuk dibaca yaitu file csv 'iris.data' dan names yang sudah didefinisikan tadi. Maka dataset yang digunakan sudah berbentuk DataFrame."
      ],
      "metadata": {
        "id": "zpk1r5V_p40I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#mendefinisikan list berisi kolom-kolom dataset\n",
        "names = ['sepal.lenght','sepal-width','petal-lenght','petal-width','class']\n",
        "\n",
        "#membaca dataset dengan library pandas\n",
        "dataset = pandas.read_csv('iris.data', names=names)"
      ],
      "metadata": {
        "id": "VY-Upp69h8sf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kemudian kode dibawah digunakan untuk menampilkan dimensi dari dataset yang telah dibaca menggunakan pandas. Dimensi dari dataset merupakan gambaran singkat mengenai banyaknya jumlah baris yang menunjukkan banyaknya sampel data dan jumlah kolom yang menunjukkan atribut data dari dataset terkait."
      ],
      "metadata": {
        "id": "7UDOL3KArEd4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# menentukan dimensi dari dataset\n",
        "print(dataset.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dN0hUEv0kjjg",
        "outputId": "a7a0b9fb-54bb-4089-9e8f-ee5d56f71d49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(150, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hasil/output yang dihasilkan adalah (150, 5) yang berarti dataset memiliki 150 baris dan 5 kolom."
      ],
      "metadata": {
        "id": "SMHxERISrHgU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Selanjutnya mencetak dataset 10 baris pertama yaitu dengan menggunakkan head untuk melihat sebagian awal dari dataset dan memahami isi data secara lebih rinci. Dapat dilihat output yang dikeluarkan adalah 10 data pertama dalam dataset."
      ],
      "metadata": {
        "id": "1g6OQsP3rV3f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# menampilkan 10 data teratas dari dataset\n",
        "print(dataset.head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cglZVMILkyrM",
        "outputId": "eb564f80-aad5-4747-c5d2-c88e506260e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   sepal.lenght  sepal-width  petal-lenght  petal-width        class\n",
            "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
            "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
            "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
            "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
            "4           5.0          3.6           1.4          0.2  Iris-setosa\n",
            "5           5.4          3.9           1.7          0.4  Iris-setosa\n",
            "6           4.6          3.4           1.4          0.3  Iris-setosa\n",
            "7           5.0          3.4           1.5          0.2  Iris-setosa\n",
            "8           4.4          2.9           1.4          0.2  Iris-setosa\n",
            "9           4.9          3.1           1.5          0.1  Iris-setosa\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**I. Membuat Validasi Dataset**\n",
        "\n",
        "Validasi dilakukan untuk mengetahui bahwa model yang dibuat bagus. Disini, kita membagi datatest yang telah dimuat menjadi dua, 80% diantaranya akan digunakan untuk melatih model dan 20% digunakan untuk data validasi. (Dataset yang digunakan berupa 150 bunga Iris pada praktikum sebelumnya)"
      ],
      "metadata": {
        "id": "n8Ot7c0Rren5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import library yang dibutuhkan\n",
        "import sklearn\n",
        "from sklearn import model_selection\n",
        "\n",
        "#menyimpan nilai-nilai pada dataset ke dalam variabel array\n",
        "array = dataset.values\n",
        "\n",
        "#menyimpan data fitur dataset pada variabel X\n",
        "X = array[:,0:4]\n",
        "\n",
        "#menyimpan data fitur dataset pada variabel Y\n",
        "Y = array[:,4]\n",
        "\n",
        "#mendefinisikan ukuran testing data dan seed\n",
        "validation_size = 0.20\n",
        "seed = 7\n",
        "\n",
        "#memisahkan data menjadi training dan testing\n",
        "X_train, X_validation, Y_train, Y_validation = model_selection.train_test_split(X, Y, test_size=validation_size, random_state=seed)"
      ],
      "metadata": {
        "id": "QcZeT8SklEdW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#mengecek data yang sudah dibagi\n",
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMGhkLFYlOsu",
        "outputId": "bbd5f725-3109-4e54-d977-dfa12596b69e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(120, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setelah perintah diatas dieksekusi, kita sudah memiliki dua data, yaitu X_train dan Y_train untuk mempersiapkan model dan rangkaian X_validation dan Y_validation ynag dapat digunakan selanjutnya."
      ],
      "metadata": {
        "id": "jSCTVraPsZiv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**II. K-Folds Cross Validation**\n",
        "\n",
        "Kita akan menggunakan validasi silang 10 kali lipat untuk memperkirakan akurasi. Untuk itu dataset dibagi menjadi 10 bagian, 9 untuk latihan dan 1 untuk pengujian dan ulangi untuk semua kombinasi."
      ],
      "metadata": {
        "id": "spN-PxySsqc_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#test options and evaluation metric\n",
        "seed = 7\n",
        "scoring = 'accuracy'"
      ],
      "metadata": {
        "id": "c1DTtlYUtqch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**III. Membangun Model**\n",
        "\n",
        "Untuk mengetahui algoritma yang cocok dengan studi kasus ini maka kita harus mengevaluasi dengan beberapa algoritma. Pada tugas praktikum kedua ini, digunakan tiga model yaitu Stochastic Gradient Descent (SGD), Decission Tree, dan Bagging Classifier."
      ],
      "metadata": {
        "id": "CdGW23_Ws900"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "\n",
        "# Spot Check Algorithms\n",
        "models = []\n",
        "models.append(('SGD', SGDClassifier()))\n",
        "models.append(('DT', DecisionTreeClassifier()))\n",
        "models.append(('BC', BaggingClassifier()))\n",
        "\n",
        "# evaluate each model in turn\n",
        "results = []\n",
        "names = []\n",
        "for name, model in models:\n",
        "  kfold = model_selection.KFold(n_splits=10, random_state=seed, shuffle=True)\n",
        "  cv_results = model_selection.cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n",
        "  results.append(cv_results)\n",
        "  names.append(name)\n",
        "  msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
        "  print(msg)"
      ],
      "metadata": {
        "id": "xdaksg0At2UV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8377498-3a7b-437c-8d13-3c7efecd7317"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SGD: 0.800000 (0.130171)\n",
            "DT: 0.950000 (0.076376)\n",
            "BC: 0.966667 (0.040825)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**IV. Memilih Model Terbaik**\n",
        "\n",
        "Jika sudah memiliki hasil evaluasi dari ketiga model diatas untuk memilih model terbaik dilakukan dari perbandingan satu sama lainnya dan dipilih yang paling akurat. Dari eksekusi script diatas, kita mendapatkan hasil mentah sebagai berikut:\n",
        "1. SGD: 0.800000 (0.130171)\n",
        "2. DT: 0.950000 (0.076376)\n",
        "3. BC: 0.966667 (0.040825)\n",
        "\n",
        "Dari hasil di atas, kita dapat melihat bahwa Bagging Classifier memiliki nilai akurasi perkiraan terbesar. Setelah mengetahui model yang paling akurat yaitu Bagging Classifier (BC), selanjutnya kita dapat mencoba melakukan pengujian tentang keakuratan model Bagging Classifier terhadap data yang ada."
      ],
      "metadata": {
        "id": "iS6FGYjXtXnN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pertama impor fungsi-fungsi yang diperlukan yang berguna untuk mengevaluasi performa model klasifikasi. Kemudian model gaus (BaggingClassifier) dilatih dengan menggunakan data X_train dan Y_train.\n",
        "Setelah itu cetak nilai akurasi dengan fungsi accuracy_score yang merupakan metrik yang mengukur sejauh mana model klasifikasi berhasil memprediksi label. Kemudian Confussion matrix adalah tabel yang digunakan untuk menggambarkan kinerja model klasifikasi dan classification_report akan mencetak laporan yang berisi precision, recall, f1-score, dan support."
      ],
      "metadata": {
        "id": "hsipdGOZ37uu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
        "\n",
        "# Make predictions on validation dataset\n",
        "gaus = BaggingClassifier()\n",
        "\n",
        "gaus.fit(X_train, Y_train)\n",
        "predictions = gaus.predict(X_validation)\n",
        "\n",
        "print('Akurasi pada Data Testing : ',accuracy_score(Y_validation, predictions))\n",
        "print('Confusion Matrix : \\n',confusion_matrix(Y_validation, predictions))\n",
        "print('\\n Classification Report : \\n',classification_report(Y_validation, predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aOPuZVuABDoc",
        "outputId": "6581414c-c982-4f36-ecbf-7ab3cceece48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Akurasi pada Data Testing :  0.9\n",
            "Confusion Matrix : \n",
            " [[ 7  0  0]\n",
            " [ 0 10  2]\n",
            " [ 0  1 10]]\n",
            "\n",
            " Classification Report : \n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "    Iris-setosa       1.00      1.00      1.00         7\n",
            "Iris-versicolor       0.91      0.83      0.87        12\n",
            " Iris-virginica       0.83      0.91      0.87        11\n",
            "\n",
            "       accuracy                           0.90        30\n",
            "      macro avg       0.91      0.91      0.91        30\n",
            "   weighted avg       0.90      0.90      0.90        30\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Kesimpulan**\n",
        "\n",
        "Dari hasil pengujian diatas, untuk dataset Bunga Iris didapatkan nilai accuracy pada data testing adalah 0.9"
      ],
      "metadata": {
        "id": "lg9nYLLYuSwF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Nomor 2\n",
        "Dataset Wine\n",
        "\n",
        "Link: http://archive.ics.uci.edu/dataset/109/wine"
      ],
      "metadata": {
        "id": "DtToXjAiVtwq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import Library yang Dibutuhkan**\n",
        "\n",
        "Pertama gunakan library pandas. Pandas merupakan sebuah library di Python yang berlisensi BSD dan open source yang menyediakan struktur data dan analisis data yang mudah digunakan."
      ],
      "metadata": {
        "id": "7o8230IMV41o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import library yang dibutuhkan\n",
        "import pandas"
      ],
      "metadata": {
        "id": "aFr-uJx2WP8C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Memuat Dataset**\n",
        "\n",
        "Pada tugas ini dataset yang digunakan adalah dataset klasifikasi Wine.\n",
        "\n",
        "Pertama definisikan variabel names untuk menyimpan nama-nama kolom atau atribut dari dataset. Setiap elemen dalam daftar names mewakili nama kolom yang ada dalam dataset.\n",
        "\n",
        "Kemudian digunakan library pandas untuk membaca dataset dari file CSV yang sudah diimport tadi yaitu dengan fungsi read_csv dan memasukkan dua argumen untuk dibaca yaitu file csv 'wine.data' dan names yang sudah didefinisikan tadi. Maka dataset yang digunakan sudah berbentuk DataFrame."
      ],
      "metadata": {
        "id": "DCRKsFKfXbuy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#mendefinisikan list berisi kolom-kolom dataset\n",
        "names = ['class', 'Alcohol', 'Malicacid', 'Ash', 'Alcalinity_of_ash', 'Magnesium', 'Total_phenols', 'Flavanoids', 'Nonflavanoid_phenols', 'Proanthocyanins']\n",
        "#membaca dataset dengan library pandas\n",
        "dataset = pandas.read_csv('wine.data', names=names)"
      ],
      "metadata": {
        "id": "ef3mwsbjWTbw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kemudian kode dibawah digunakan untuk menampilkan dimensi dari dataset yang telah dibaca menggunakan pandas. Dimensi dari dataset merupakan gambaran singkat mengenai banyaknya jumlah baris yang menunjukkan banyaknya sampel data dan jumlah kolom yang menunjukkan atribut data dari dataset terkait."
      ],
      "metadata": {
        "id": "IuD4NIeiXpWs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#menentukan dimensi dari dataset\n",
        "print(dataset.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asPQghPjWbb3",
        "outputId": "ffbed748-c9f2-40cc-8e05-fb5de9ca92e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(178, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hasil/output yang dihasilkan adalah (178, 10) yang berarti dataset memiliki 178 baris dan 10 kolom."
      ],
      "metadata": {
        "id": "OcsU-H4ZXu9L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Selanjutnya mencetak dataset 10 baris pertama yaitu dengan menggunakkan head untuk melihat sebagian awal dari dataset dan memahami isi data secara lebih rinci. Dapat dilihat output yang dikeluarkan adalah 10 data pertama dalam dataset."
      ],
      "metadata": {
        "id": "mSuL5dD8X4wp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#menampilkan 10 data teratas dari dataset\n",
        "print(dataset.head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOe1inXEWelp",
        "outputId": "535e4bc8-425d-4cc4-ac17-d024e804b7c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   class  Alcohol  Malicacid   Ash  Alcalinity_of_ash  \\\n",
            "1 14.23 1.71 2.43   15.6      127       2.80  3.06               0.28   \n",
            "  13.20 1.78 2.14   11.2      100       2.65  2.76               0.26   \n",
            "  13.16 2.36 2.67   18.6      101       2.80  3.24               0.30   \n",
            "  14.37 1.95 2.50   16.8      113       3.85  3.49               0.24   \n",
            "  13.24 2.59 2.87   21.0      118       2.80  2.69               0.39   \n",
            "  14.20 1.76 2.45   15.2      112       3.27  3.39               0.34   \n",
            "  14.39 1.87 2.45   14.6       96       2.50  2.52               0.30   \n",
            "  14.06 2.15 2.61   17.6      121       2.60  2.51               0.31   \n",
            "  14.83 1.64 2.17   14.0       97       2.80  2.98               0.29   \n",
            "  13.86 1.35 2.27   16.0       98       2.98  3.15               0.22   \n",
            "\n",
            "                   Magnesium  Total_phenols  Flavanoids  Nonflavanoid_phenols  \\\n",
            "1 14.23 1.71 2.43       2.29           5.64        1.04                  3.92   \n",
            "  13.20 1.78 2.14       1.28           4.38        1.05                  3.40   \n",
            "  13.16 2.36 2.67       2.81           5.68        1.03                  3.17   \n",
            "  14.37 1.95 2.50       2.18           7.80        0.86                  3.45   \n",
            "  13.24 2.59 2.87       1.82           4.32        1.04                  2.93   \n",
            "  14.20 1.76 2.45       1.97           6.75        1.05                  2.85   \n",
            "  14.39 1.87 2.45       1.98           5.25        1.02                  3.58   \n",
            "  14.06 2.15 2.61       1.25           5.05        1.06                  3.58   \n",
            "  14.83 1.64 2.17       1.98           5.20        1.08                  2.85   \n",
            "  13.86 1.35 2.27       1.85           7.22        1.01                  3.55   \n",
            "\n",
            "                   Proanthocyanins  \n",
            "1 14.23 1.71 2.43             1065  \n",
            "  13.20 1.78 2.14             1050  \n",
            "  13.16 2.36 2.67             1185  \n",
            "  14.37 1.95 2.50             1480  \n",
            "  13.24 2.59 2.87              735  \n",
            "  14.20 1.76 2.45             1450  \n",
            "  14.39 1.87 2.45             1290  \n",
            "  14.06 2.15 2.61             1295  \n",
            "  14.83 1.64 2.17             1045  \n",
            "  13.86 1.35 2.27             1045  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**I. Membuat Validasi Dataset**\n",
        "\n",
        "Validasi dilakukan untuk mengetahui bahwa model yang dibuat bagus. Disini, kita membagi datatest yang telah dimuat menjadi dua, 80% diantaranya akan digunakan untuk melatih model dan 20% digunakan untuk data validasi. (Dataset yang digunakan berupa 178 data Wine)"
      ],
      "metadata": {
        "id": "Iad-0yVBYoxp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import library yang dibutuhkan\n",
        "import sklearn\n",
        "from sklearn import model_selection\n",
        "\n",
        "#menyimpan nilai-nilai pada dataset ke dalam variabel array\n",
        "array = dataset.values\n",
        "\n",
        "X = array[:,0:9]\n",
        "\n",
        "Y = array[:,1]\n",
        "\n",
        "validation_size = 0.20\n",
        "seed = 7\n",
        "\n",
        "#memisahkan data menjadi training dan testing\n",
        "X_train, X_validation, Y_train, Y_validation = model_selection.train_test_split(X, Y, test_size=validation_size, random_state=seed)\n",
        "\n",
        "#mengecek data yang sudah dibagi\n",
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpxGYOhOWiC0",
        "outputId": "caa2627b-9541-475d-d736-10321f3b99c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(142, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setelah perintah diatas dieksekusi, kita sudah memiliki dua data, yaitu X_train dan Y_train untuk mempersiapkan model dan rangkaian X_validation dan Y_validation ynag dapat digunakan selanjutnya."
      ],
      "metadata": {
        "id": "Lbe3SfICZAjg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**II. K-Folds Cross Validation**\n",
        "\n",
        "Kita akan menggunakan validasi silang 10 kali lipat untuk memperkirakan akurasi. Untuk itu dataset dibagi menjadi 10 bagian, 9 untuk latihan dan 1 untuk pengujian dan ulangi untuk semua kombinasi."
      ],
      "metadata": {
        "id": "u8UViVLvZQre"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#test options and evaluation metric\n",
        "seed = 7\n",
        "scoring = 'accuracy'"
      ],
      "metadata": {
        "id": "tn_PkxKCWm9o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**III. Membangun Model**\n",
        "\n",
        "Untuk mengetahui algoritma yang cocok dengan studi kasus ini maka kita harus mengevaluasi dengan beberapa algoritma. Pada tugas praktikum kedua ini, digunakan tiga model yaitu K-Nearest Neughbors (KNN), Gaussian Naive Bayes (NB), dan Support Vector Machines (SVM)."
      ],
      "metadata": {
        "id": "b1KhdJWLZU_r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import library yang dibutuhkan\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "#spot check algorithms\n",
        "models = []\n",
        "models.append(('KNN', KNeighborsClassifier()))\n",
        "models.append(('NB', GaussianNB()))\n",
        "models.append(('SVM', SVC()))\n",
        "\n",
        "#evaluate each model in turn\n",
        "results = []\n",
        "names = []\n",
        "for name, model in models:\n",
        "  kfold = model_selection.KFold(n_splits=10, random_state=seed, shuffle=True)\n",
        "  cv_results = model_selection.cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n",
        "  results.append(cv_results)\n",
        "  names.append(name)\n",
        "  msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
        "  print(msg)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1QjGpRjTWqb1",
        "outputId": "5359c49c-6ec9-4b56-c070-da88854f42eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN: 0.289524 (0.122647)\n",
            "NB: 0.704762 (0.073925)\n",
            "SVM: 0.050000 (0.055787)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**IV. Memilih Model Terbaik**\n",
        "\n",
        "Jika sudah memiliki hasil evaluasi dari ketiga model diatas untuk memilih model terbaik dilakukan dari perbandingan satu sama lainnya dan dipilih yang paling akurat. Dari eksekusi script diatas, kita mendapatkan hasil mentah sebagai berikut:\n",
        "1. KNN: 0.289524 (0.122647)\n",
        "2. NB: 0.704762 (0.073925)\n",
        "3. SVM: 0.050000 (0.055787)\n",
        "\n",
        "Dari hasil di atas, kita dapat melihat bahwa Gaussian Naive Bayes (NB) memiliki nilai akurasi perkiraan terbesar. Setelah mengetahui model yang paling akurat yaitu Gaussian Naive Bayes (NB), selanjutnya kita dapat mencoba melakukan pengujian tentang keakuratan model Gaussian Naive Bayes terhadap data yang ada."
      ],
      "metadata": {
        "id": "aWcQWElIZuBS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pertama impor fungsi-fungsi yang diperlukan yang berguna untuk mengevaluasi performa model klasifikasi. Kemudian model nb (GaussianNB) dilatih dengan menggunakan data X_train dan Y_train.\n",
        "Setelah itu cetak nilai akurasi dengan fungsi accuracy_score yang merupakan metrik yang mengukur sejauh mana model klasifikasi berhasil memprediksi label. Kemudian Confussion matrix adalah tabel yang digunakan untuk menggambarkan kinerja model klasifikasi dan classification_report akan mencetak laporan yang berisi precision, recall, f1-score, dan support."
      ],
      "metadata": {
        "id": "ejOA7s6H5FtW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import library yang dibutuhkan\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# make predictions on validation dataset\n",
        "nb = GaussianNB()\n",
        "nb.fit(X_train, Y_train)\n",
        "predictions = nb.predict(X_validation)\n",
        "print('Akurasi pada Data Testing : ', accuracy_score(Y_validation, predictions))\n",
        "print('Confusion Matrix : \\n',confusion_matrix(Y_validation, predictions))\n",
        "print('\\n Classification Report : \\n',classification_report(Y_validation, predictions, zero_division=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFw5w6gdWsse",
        "outputId": "1948cc9f-c54a-4532-e31f-d46e6e64a2f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Akurasi pada Data Testing :  0.8611111111111112\n",
            "Confusion Matrix : \n",
            " [[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]]\n",
            "\n",
            " Classification Report : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "        78.0       1.00      1.00      1.00         1\n",
            "        85.0       1.00      1.00      1.00         4\n",
            "        86.0       1.00      1.00      1.00         3\n",
            "        87.0       1.00      1.00      1.00         1\n",
            "        88.0       1.00      1.00      1.00         3\n",
            "        89.0       1.00      1.00      1.00         1\n",
            "        90.0       1.00      1.00      1.00         2\n",
            "        91.0       1.00      0.00      0.00         1\n",
            "        92.0       0.50      1.00      0.67         1\n",
            "        94.0       1.00      1.00      1.00         2\n",
            "        96.0       1.00      1.00      1.00         2\n",
            "        98.0       0.50      1.00      0.67         1\n",
            "        99.0       1.00      0.00      0.00         1\n",
            "       101.0       1.00      1.00      1.00         2\n",
            "       102.0       1.00      1.00      1.00         1\n",
            "       104.0       1.00      1.00      1.00         1\n",
            "       106.0       1.00      1.00      1.00         2\n",
            "       107.0       1.00      1.00      1.00         1\n",
            "       110.0       1.00      1.00      1.00         1\n",
            "       111.0       1.00      1.00      1.00         1\n",
            "       120.0       0.50      1.00      0.67         1\n",
            "       123.0       1.00      0.00      0.00         1\n",
            "       132.0       0.00      1.00      0.00         0\n",
            "       134.0       1.00      0.00      0.00         1\n",
            "       136.0       1.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.86        36\n",
            "   macro avg       0.90      0.80      0.72        36\n",
            "weighted avg       0.96      0.86      0.83        36\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Kesimpulan**\n",
        "\n",
        "Dari hasil pengujian di atas, untuk dataset Wine didapatkan nilai accuracy pada data testing adalah 0.8611111111111112"
      ],
      "metadata": {
        "id": "vnY8mQ5sagOw"
      }
    }
  ]
}